import os
import sys

import google.generativeai as genai

import fractale.agent.defaults as defaults
import fractale.utils as utils


class Agent:
    """
    A base for an agent. Each agent should:

    1. Have a run function that accepts (and modifies) a context.
    2. Set the context.result as the final result (or set to None)
      - On failure, set context.result to the error context.
    3. Set any other variables needed by future build steps.
    4. Have a get_prompt function that takes the same input as run,
       but returns the prompt for the LLM. This can be modified by
       the manager.
    5. Receiving a prompt in the context should use it instead.
       This indicates the manager has set it.
    """

    # name and description should be on the class

    def __init__(self):

        # Max attempts defaults to unlimited
        # We start counting at 1 for the user to see.
        # Eat your heart out, Matlab.
        self.attempts = 1
        self.max_attempts = None

        # Custom initialization functions
        self.init()

    def init(self):
        pass

    def return_on_failure(self):
        """
        On failure, have we reached max attempts and should return?
        """
        # Unset or 0.
        if not self.max_attempts:
            return False
        # This starts counting at 1, so we check >=
        return self.attempts >= self.max_attempts

    def set_max_attempts(self, max_attempts):
        self.max_attempts = max_attempts

    def add_arguments(self, subparser):
        """
        Add arguments for the agent to show up in argparse

        This is added by the plugin class
        """
        assert subparser

    def write_file(self, context, content, add_comment=True):
        """
        Shared function to write content to file, if context.outfile is defined.
        """
        outfile = context.get("outfile")
        if not outfile:
            return
        # Add generation line
        if add_comment:
            content += f"\n# Generated by fractale {self.name} agent"
        utils.write_file(content, outfile)

    def get_code_block(self, content, code_type):
        """
        Parse a code block from the response
        """
        if content.startswith(f"```{code_type}"):
            content = content[len(f"```{code_type}") :]
        if content.startswith("```"):
            content = content[len("```") :]
        if content.endswith("```"):
            content = content[: -len("```")]
        return content

    def get_result(self, context):
        """
        Return either the entire context or single result.
        """
        if context.is_managed:
            return context
        return context.result

    def run(self, context):
        """
        Run the agent.
        """
        assert context
        raise NotImplementedError(f"The {self.name} agent is missing a 'run' function")

    def get_initial_prompt(self, context):
        """
        Get the initial prompt (with details) to provide context to the manager.

        If we don't do this, the manager can provide a bad instruction for how to fix the error.
        """
        return self.get_prompt(context)

    def get_prompt(self, context):
        """
        This function should take the same context as run and return the parsed prompt that
        would be used. We do this so we can hand it to the manager for tweaking.
        """
        assert context
        raise NotImplementedError(f"The {self.name} agent is missing a 'get_prompt' function")


class GeminiAgent(Agent):
    """
    A base for an agent that uses the Gemini API.
    """

    def init(self):
        self.model = genai.GenerativeModel(defaults.gemini_model)
        self.chat = self.model.start_chat()
        try:
            genai.configure(api_key=os.environ["GEMINI_API_KEY"])
        except KeyError:
            sys.exit("ERROR: GEMINI_API_KEY environment variable not set.")

    def ask_gemini(self, prompt, with_history=True):
        """
        Ask gemini adds a wrapper with some error handling.
        """
        try:
            if with_history:
                response = self.chat.send_message(prompt)
            else:
                response = self.model.generate_content(prompt)

            # This line can fail. If it succeeds, return entire response
            return response.text.strip()

        except ValueError as e:
            print(f"[Error] The API response was blocked and contained no text: {str(e)}")
            return "GEMINI ERROR: The API returned an error (or stop) and we need to try again."
