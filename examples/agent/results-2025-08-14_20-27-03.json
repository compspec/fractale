[
    [
        "build",
        269.075115828,
        "# syntax=docker/dockerfile:1\n\n#\n# Dockerfile for LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator)\n#\n# Target Environment: Google Cloud CPU instance in Kubernetes\n# Base Image: Ubuntu 22.04 LTS (Jammy Jellyfish)\n#\n\nFROM ubuntu:22.04\n\n# Set non-interactive frontend for package installations to avoid prompts\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install essential build tools, Git, CMake, MPI, and other dependencies.\n# OpenMPI is crucial for parallel execution in containerized environments.\n# FIX: Add python3, which is a required build-time dependency for LAMMPS's CMake scripts.\n# Clean up apt cache in the same layer to reduce image size.\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    build-essential \\\n    cmake \\\n    git \\\n    openmpi-bin \\\n    libopenmpi-dev \\\n    libfftw3-dev \\\n    ca-certificates \\\n    python3 \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set the primary working directory for the container.\n# This directory will hold the example input files.\nWORKDIR /app\n\n# This single RUN command performs all steps to build and install LAMMPS.\n# This adheres to the no-multi-stage and no-COPY/ADD constraints.\n# 1. Clones the latest stable version of LAMMPS into a temporary directory.\n# 2. Moves the required example files into the WORKDIR (/app).\n# 3. Configures the build using CMake, enabling MPI and specific LAMMPS packages.\n#    - PKG_REAXFF is enabled as requested by the example files.\n#    - PKG_KSPACE is a common package that uses the FFTW library.\n#    - Installs to /usr/local, which is on the default PATH.\n# 4. Compiles LAMMPS using all available CPU cores.\n# 5. Installs the 'lmp' executable.\n# 6. Cleans up the source code to minimize the final image size.\nRUN \\\n    # Define a temporary source directory\n    SRC_DIR=/tmp/lammps-src && \\\n    \\\n    # Clone the latest stable branch of LAMMPS\n    git clone --depth 1 --branch stable https://github.com/lammps/lammps.git ${SRC_DIR} && \\\n    \\\n    # Move the specified example files into the current WORKDIR (/app)\n    # This fulfills the requirement to have these files present without using COPY/ADD.\n    mv ${SRC_DIR}/examples/reaxff/HNS/* . && \\\n    \\\n    # Create a build directory and navigate into it\n    mkdir -p ${SRC_DIR}/build && \\\n    cd ${SRC_DIR}/build && \\\n    \\\n    # Configure the LAMMPS build with CMake\n    cmake ../cmake \\\n      -D CMAKE_INSTALL_PREFIX=/usr/local \\\n      -D CMAKE_BUILD_TYPE=Release \\\n      -D BUILD_MPI=yes \\\n      -D PKG_REAXFF=yes \\\n      -D PKG_KSPACE=yes \\\n      -D PKG_MOLECULE=yes && \\\n    \\\n    # Compile LAMMPS using the number of available processors\n    make -j$(nproc) && \\\n    \\\n    # Install the LAMMPS executable ('lmp') to /usr/local/bin\n    make install && \\\n    \\\n    # Remove the temporary source directory to keep the image clean\n    rm -rf ${SRC_DIR}\n\n# Set the container's entrypoint to the LAMMPS executable.\n# The executable 'lmp' is located in /usr/local/bin, which is in the system PATH.\n# This allows users to run simulations by passing LAMMPS arguments directly to the container.\n# For example: docker run <image_name> -in in.hns\nENTRYPOINT [\"lmp\"]"
    ],
    [
        "kubernetes-job",
        89.67917267800294,
        "# This manifest creates a Kubernetes Job to run a single LAMMPS simulation.\n# It is designed for a GCE CPU-based Kubernetes environment (like GKE).\n# See https://kubernetes.io/docs/concepts/workloads/controllers/job/\napiVersion: batch/v1\nkind: Job\nmetadata:\n  # The name of the Job. Must be unique within the namespace.\n  name: lammps-hns-job\n  # This Job will be deployed to the 'default' namespace as none is specified.\nspec:\n  # The backoff limit specifies the number of retries before considering a Job as failed.\n  # Setting to 1 means it will try once and if it fails, it will not be retried.\n  backoffLimit: 1\n  # The template for the Pod that the Job will create.\n  template:\n    spec:\n      # The restart policy for the Pod. For Jobs, this must be 'OnFailure' or 'Never'.\n      # 'OnFailure' ensures the Job controller handles retries up to the backoffLimit.\n      restartPolicy: OnFailure\n      containers:\n      - name: lammps # The exact container name as requested.\n        # Image name corrected to 'lammps', referring to a locally available image\n        # as required by the imagePullPolicy.\n        image: lammps\n        # imagePullPolicy: Never requires the image to be pre-pulled on the node.\n        # The Job will fail if the image is not locally present.\n        imagePullPolicy: Never\n        # Resource requests and limits are critical for production workloads on cloud environments.\n        # They ensure predictable performance and stable node operation.\n        # These are sensible defaults for a single-core CPU-bound scientific computing task.\n        resources:\n          requests:\n            cpu: \"1\"\n            memory: \"2Gi\"\n          limits:\n            cpu: \"1\"\n            memory: \"2Gi\"\n        # The command to run in the container.\n        # It is best practice to separate the command from its arguments.\n        command: [\"lmp\"]\n        # The arguments passed to the 'lmp' command.\n        # This executes the 'in.reaxff.hns' input script, which is expected to be\n        # in the container's working directory.\n        args:\n        - \"-v\"\n        - \"x\"\n        - \"2\"\n        - \"-v\"\n        - \"y\"\n        - \"2\"\n        - \"-v\"\n        - \"z\"\n        - \"2\"\n        - \"-in\"\n        - \"./in.reaxff.hns\"\n        - \"-nocite\""
    ]
]