import fractale.utils as utils


class Agent:
    """
    A base for an agent. Each agent should:

    1. Have a run function that accepts (and modifies) a context.
    2. Set the context.result as the final result (or set to None)
      - On failure, set context.result to the error context.
    3. Set any other variables needed by future build steps.
    4. Have a get_prompt function that takes the same input as run,
       but returns the prompt for the LLM. This can be modified by
       the manager.
    5. Receiving a prompt in the context should use it instead.
       This indicates the manager has set it.
    """

    # name and description should be on the class

    def __init__(self):

        # Max attempts defaults to unlimited
        # We start counting at 1 for the user to see.
        # Eat your heart out, Matlab.
        self.attempts = 1
        self.max_attempts = None

        # Custom initialization functions
        self.init()

    def init(self):
        pass

    def return_on_failure(self):
        """
        On failure, have we reached max attempts and should return?
        """
        if not self.max_attempts:
            return False
        return self.attempts > self.max_attempts

    def set_max_attempts(self, max_attempts):
        self.max_attempts = max_attempts

    def add_arguments(self, subparser):
        """
        Add arguments for the agent to show up in argparse

        This is added by the plugin class
        """
        assert subparser

    def write_file(self, context, content, add_comment=True):
        """
        Shared function to write content to file, if context.outfile is defined.
        """
        outfile = context.get("outfile")
        if not outfile:
            return
        # Add generation line
        if add_comment:
            content += f"\n# Generated by fractale {self.name} agent"
        utils.write_file(content, outfile)

    def ask_gemini(self, prompt):
        """
        Ask gemini adds a wrapper with some error handling.
        """
        try:
            response = self.chat.send_message(prompt)

            # This line can fail. If it succeeds, return entire response
            text_content = response.text
            assert text_content
            return response

        except ValueError as e:
            print(f"[Error] The API response was blocked and contained no text: {str(e)}")

            print("VANESSA DEBUG WHAT TO DO")
            import IPython

            IPython.embed()
            # We probably want to retry if it is 1 (STOP) and empty.
            # Otherwise we need to somehow retry fixing the dockerfile.
            # For robust logging, you can inspect the reason.
            if response.candidates:
                finish_reason = response.candidates[0].finish_reason.name
                print(f"Finish Reason: {finish_reason}")

    def run(self, context):
        """
        Run the agent.
        """
        assert context
        raise NotImplementedError(f"The {self.name} agent is missing a 'run' function")

    def get_prompt(self, context):
        """
        This function should take the same context as run and return the parsed prompt that
        would be used. We do this so we can hand it to the manager for tweaking.
        """
        assert context
        raise NotImplementedError(f"The {self.name} agent is missing a 'get_prompt' function")
